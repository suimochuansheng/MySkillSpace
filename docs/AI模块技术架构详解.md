# SkillSpace AIæ¨¡å—æŠ€æœ¯æ¶æ„è¯¦è§£

## ğŸ“Œ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æ‹†è§£ SkillSpace é¡¹ç›®ä¸­ AI æ¨¡å—çš„æŠ€æœ¯å®ç°ï¼ŒåŒ…æ‹¬ï¼š
- **AIæ¨¡å‹éƒ¨ç½²æ–¹æ¡ˆ**ï¼ˆæœ¬åœ° Qwen æ¨¡å‹ï¼‰
- **é˜¿é‡Œäº‘åƒé—®æ¥å£è°ƒç”¨**ï¼ˆå…¼å®¹æ–¹æ¡ˆï¼‰
- **å¼‚æ­¥æ¶æ„è®¾è®¡**ï¼ˆCelery + WebSocket + Redisï¼‰
- **æµå¼è¾“å‡ºå®ç°**ï¼ˆSSE å’Œ WebSocket åŒæ¨¡å¼ï¼‰
- **å®Œæ•´çš„æ¶æ„å…³ç³»å›¾**

---

## ğŸ—ï¸ æ•´ä½“æ¶æ„æ¦‚è§ˆ

### æ¶æ„åˆ†å±‚å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         å‰ç«¯å±‚ (Vue3)                            â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  EventSource     â”‚        â”‚  WebSocket       â”‚              â”‚
â”‚  â”‚  (SSEæµå¼æ¥æ”¶)    â”‚        â”‚  (å®æ—¶åŒå‘é€šä¿¡)   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ HTTP SSE                 â”‚ WS Protocol
            â†“                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           â”‚         Django ASGI (Daphne)                        â”‚
â”‚           â”‚                          â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  QwenChatAPI     â”‚       â”‚  AIChatConsumer    â”‚            â”‚
â”‚  â”‚  (RESTè§†å›¾)       â”‚       â”‚  (WebSocketæ¶ˆè´¹è€…)  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                          â”‚                          â”‚
â”‚           â”‚ è°ƒç”¨æ¨¡å‹                  â”‚ ç›‘å¬Channel              â”‚
â”‚           â”‚                          â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ model_loader.py  â”‚       â”‚  Channel Layer     â”‚            â”‚
â”‚  â”‚ (æœ¬åœ°æ¨¡å‹åŠ è½½)    â”‚       â”‚  (Redisæ¶ˆæ¯é˜Ÿåˆ—)    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚ group_send()
                                       â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Celery Worker          â”‚                          â”‚
â”‚                                      â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  qwen_chat_task_streaming                             â”‚    â”‚
â”‚  â”‚  (å¼‚æ­¥AIæ¨ç†ä»»åŠ¡)                                      â”‚    â”‚
â”‚  â”‚                                                        â”‚    â”‚
â”‚  â”‚  1. æ¥æ”¶ä»»åŠ¡å‚æ•°                                       â”‚    â”‚
â”‚  â”‚  2. è°ƒç”¨ stream_generate_answer()                    â”‚    â”‚
â”‚  â”‚  3. é€tokenæ¨é€åˆ° Redis Channel                       â”‚    â”‚
â”‚  â”‚  4. WebSocket Consumer è½¬å‘ç»™å‰ç«¯                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â†‘                                  â”‚
â”‚                              â”‚ æ¶ˆæ¯é˜Ÿåˆ— (AMQP)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       æ¶ˆæ¯ä¸­é—´ä»¶å±‚                               â”‚
â”‚                              â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  RabbitMQ    â”‚   â”‚  Redis         â”‚   â”‚  MySQL       â”‚     â”‚
â”‚  â”‚  (ä»»åŠ¡é˜Ÿåˆ—)   â”‚   â”‚  (Channel Layer)â”‚   â”‚  (æ•°æ®å­˜å‚¨)   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” æ ¸å¿ƒæŠ€æœ¯å®ç°æ‹†è§£

### ä¸€ã€AIæ¨¡å‹éƒ¨ç½²æ–¹æ¡ˆ

#### 1.1 æ¨¡å‹åŠ è½½å™¨è®¾è®¡ (model_loader.py)

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- âœ… **å•ä¾‹æ¨¡å¼**ï¼šå…¨å±€åªåŠ è½½ä¸€æ¬¡æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½
- âœ… **4-bité‡åŒ–**ï¼šä½¿ç”¨ BitsAndBytes é‡åŒ–ï¼ŒèŠ‚çœæ˜¾å­˜ï¼ˆ7Bæ¨¡å‹ä»…éœ€~4GBï¼‰
- âœ… **æœ¬åœ°ç¼“å­˜**ï¼šè·³è¿‡ç½‘ç»œæ ¡éªŒï¼Œç›´æ¥åŠ è½½æœ¬åœ°æ¨¡å‹
- âœ… **CUDAä¼˜åŒ–**ï¼šå¯ç”¨ cuDNNã€TF32ã€Flash Attention 2
- âœ… **ç¯å¢ƒå˜é‡æ§åˆ¶**ï¼šæ”¯æŒå¼€å‘ç¯å¢ƒç¦ç”¨AIåŠ å¿«å¯åŠ¨

**åŠ è½½æµç¨‹**ï¼š

```python
# 1. æ¨¡å‹é…ç½®
MODEL_NAME = "Qwen/Qwen2.5-7B-Instruct"
DEVICE = "cuda:0" if torch.cuda.is_available() else "cpu"
MODEL_CACHE_DIR = os.path.join(BASE_DIR, "qwen_model_cache")

# 2. ç¯å¢ƒå˜é‡æ§åˆ¶
ENABLE_MODEL_LOADING = os.getenv("ENABLE_AI_MODEL", "true").lower() == "true"

# 3. CUDAæ€§èƒ½ä¼˜åŒ–
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True  # cuDNNè‡ªåŠ¨è°ƒä¼˜
    torch.backends.cuda.matmul.allow_tf32 = True  # TF32åŠ é€Ÿ
    torch.cuda.empty_cache()  # æ¸…ç†æ˜¾å­˜

# 4. é‡åŒ–é…ç½®ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,                      # å¯ç”¨4-bité‡åŒ–
    bnb_4bit_compute_dtype=torch.float16,   # è®¡ç®—ç²¾åº¦
    bnb_4bit_use_double_quant=False,        # å…³é—­åŒé‡é‡åŒ–ï¼ˆåŠ å¿«å¯åŠ¨ï¼‰
    bnb_4bit_quant_type="nf4",              # NF4é‡åŒ–ç±»å‹
)

# 5. åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    model_dir,
    device_map="cuda:0",          # ç›´æ¥æŒ‡å®šè®¾å¤‡
    trust_remote_code=True,
    quantization_config=bnb_config,
    local_files_only=True,        # è·³è¿‡è”ç½‘éªŒè¯
    attn_implementation="flash_attention_2"  # Flash Attention 2
).eval()
```

**å…³é”®ä¼˜åŒ–ç‚¹**ï¼š

| ä¼˜åŒ–é¡¹ | ä½œç”¨ | æ•ˆæœ |
|--------|------|------|
| **4-bité‡åŒ–** | å‹ç¼©æ¨¡å‹æƒé‡ | æ˜¾å­˜å ç”¨ä»14GBé™è‡³4GB |
| **Flash Attention 2** | ä¼˜åŒ–æ³¨æ„åŠ›è®¡ç®— | æ¨ç†é€Ÿåº¦æå‡20%-30% |
| **local_files_only** | è·³è¿‡ç½‘ç»œæ ¡éªŒ | å¯åŠ¨æ—¶é—´å‡å°‘10-20ç§’ |
| **TF32åŠ é€Ÿ** | GPUç¡¬ä»¶åŠ é€Ÿ | çŸ©é˜µè¿ç®—é€Ÿåº¦æå‡3x |
| **å…³é—­åŒé‡é‡åŒ–** | å‡å°‘åˆå§‹åŒ–å¼€é”€ | å¯åŠ¨æ—¶é—´å‡å°‘5-10ç§’ |

---

#### 1.2 æµå¼ç”Ÿæˆå®ç°

**æ ¸å¿ƒæœºåˆ¶**ï¼šä½¿ç”¨ `TextIteratorStreamer` å®ç°é€tokenç”Ÿæˆ

```python
def stream_generate_answer(prompt: str, history: list = None):
    """
    æµå¼ç”Ÿæˆç­”æ¡ˆ

    å·¥ä½œåŸç†ï¼š
    1. ä½¿ç”¨ TextIteratorStreamer åˆ›å»ºæµå¼è¾“å‡ºå™¨
    2. åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œæ¨¡å‹æ¨ç†
    3. ä¸»çº¿ç¨‹ä» streamer è¿­ä»£è·å– token
    4. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ <thinking> å’Œ <answer> æ ‡è®°
    """

    # 1. å‡†å¤‡è¾“å…¥
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    messages.extend(history[-10:])  # é™åˆ¶å†å²é•¿åº¦
    messages.append({"role": "user", "content": prompt})

    text = tokenizer.apply_chat_template(messages, tokenize=False)
    inputs = tokenizer([text], return_tensors="pt").to(DEVICE)

    # 2. åˆ›å»ºæµå¼è¾“å‡ºå™¨
    streamer = TextIteratorStreamer(
        tokenizer,
        skip_prompt=True,           # ä¸è¾“å‡ºpromptéƒ¨åˆ†
        skip_special_tokens=True    # è·³è¿‡ç‰¹æ®Štoken
    )

    # 3. ç”Ÿæˆå‚æ•°ä¼˜åŒ–
    generation_kwargs = dict(
        inputs,
        streamer=streamer,
        max_new_tokens=2048,        # æœ€å¤§ç”Ÿæˆé•¿åº¦
        do_sample=True,
        temperature=0.7,            # æ¸©åº¦å‚æ•°
        top_p=0.8,                  # æ ¸é‡‡æ ·
        top_k=40,                   # Top-Ké‡‡æ ·
        repetition_penalty=1.1,     # é‡å¤æƒ©ç½š
        use_cache=True,             # âœ… å¯ç”¨KVç¼“å­˜ï¼ˆé‡è¦ï¼ï¼‰
    )

    # 4. å¯åŠ¨ç”Ÿæˆçº¿ç¨‹
    thread = Thread(target=model.generate, kwargs=generation_kwargs)
    thread.start()

    # 5. é€tokenè§£æå¹¶æ¨é€
    current_type = "thinking"
    buffer = ""

    for new_text in streamer:
        buffer += new_text

        # æ­£åˆ™è§£æ <thinking>...</thinking> å’Œ <answer>...</answer>
        if thinking_start_pattern.search(buffer):
            current_type = "thinking"
            buffer = re.sub(r'.*?<thinking>', '', buffer)

        if answer_start_pattern.search(buffer):
            current_type = "answer"
            buffer = re.sub(r'.*?<answer>', '', buffer)

        # æ¨é€token
        if buffer and not buffer.endswith('<'):
            yield {"token": buffer, "type": current_type}
            buffer = ""

    # 6. å‘é€ç»“æŸä¿¡å·
    yield {"token": "", "type": "finish"}
```

**XMLæ ‡è®°è§£æç¤ºä¾‹**ï¼š

```
æ¨¡å‹è¾“å‡ºï¼š
<thinking>
åˆ†æç”¨æˆ·é—®é¢˜...
éœ€è¦ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢å›ç­”...
</thinking>
<answer>
Pythonæ˜¯ä¸€é—¨é«˜çº§ç¼–ç¨‹è¯­è¨€...
</answer>

è§£æç»“æœï¼š
â†’ {"token": "åˆ†æç”¨æˆ·é—®é¢˜...", "type": "thinking"}
â†’ {"token": "éœ€è¦ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢å›ç­”...", "type": "thinking"}
â†’ {"token": "Pythonæ˜¯ä¸€é—¨é«˜çº§ç¼–ç¨‹è¯­è¨€...", "type": "answer"}
â†’ {"token": "", "type": "finish"}
```

---

### äºŒã€é˜¿é‡Œäº‘åƒé—®æ¥å£è°ƒç”¨ï¼ˆå…¼å®¹æ–¹æ¡ˆï¼‰

è™½ç„¶å½“å‰ä»£ç ä½¿ç”¨**æœ¬åœ°Qwenæ¨¡å‹**ï¼Œä½†æ¶æ„æ”¯æŒè½»æ¾åˆ‡æ¢åˆ°**é˜¿é‡Œäº‘ç™¾ç‚¼API**ã€‚

#### 2.1 åˆ‡æ¢åˆ°é˜¿é‡Œäº‘APIçš„å®ç°

```python
# backend/SkillSpace/myapps/ai_demo/alibaba_api.py

import os
from openai import OpenAI

class AlibabaDashScopeEngine:
    """
    é˜¿é‡Œäº‘ç™¾ç‚¼ API å¼•æ“
    å…¼å®¹ OpenAI SDK
    """

    def __init__(self):
        self.client = OpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )
        self.model = "qwen-plus"  # æˆ– qwen-turboã€qwen-max

    def stream_generate(self, prompt, history=None):
        """
        æµå¼ç”Ÿæˆï¼ˆè°ƒç”¨é˜¿é‡Œäº‘APIï¼‰
        """
        messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        if history:
            messages.extend(history[-10:])
        messages.append({"role": "user", "content": prompt})

        # è°ƒç”¨é˜¿é‡Œäº‘æµå¼API
        completion = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            stream=True,
            temperature=0.7,
            max_tokens=2048
        )

        # é€chunkæ¨é€
        for chunk in completion:
            if chunk.choices[0].delta.content:
                token = chunk.choices[0].delta.content
                yield {"token": token, "type": "answer"}

        yield {"token": "", "type": "finish"}
```

#### 2.2 é…ç½®åˆ‡æ¢

```python
# settings.py
AI_ENGINE_TYPE = os.getenv("AI_ENGINE", "local")  # local | alibaba | openai

# model_loader.py
def get_ai_engine():
    if AI_ENGINE_TYPE == "alibaba":
        from .alibaba_api import AlibabaDashScopeEngine
        return AlibabaDashScopeEngine()
    elif AI_ENGINE_TYPE == "local":
        return LocalQwenEngine()
    else:
        raise ValueError(f"æœªçŸ¥çš„AIå¼•æ“ç±»å‹: {AI_ENGINE_TYPE}")
```

---

### ä¸‰ã€å¼‚æ­¥æ¶æ„è®¾è®¡è¯¦è§£

#### 3.1 ä¸¤ç§å¼‚æ­¥æ–¹æ¡ˆå¯¹æ¯”

é¡¹ç›®å®ç°äº†**ä¸¤ç§å¼‚æ­¥æ¶æ„**ï¼Œæ”¯æŒä¸åŒçš„ä½¿ç”¨åœºæ™¯ï¼š

| æ–¹æ¡ˆ | æŠ€æœ¯æ ˆ | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|------|--------|---------|------|------|
| **æ–¹æ¡ˆA** | Django + SSE | APIè°ƒç”¨ã€è„šæœ¬é›†æˆ | å®ç°ç®€å•ã€æ— éœ€WebSocket | å•å‘é€šä¿¡ã€ä¸æ”¯æŒå¿ƒè·³ |
| **æ–¹æ¡ˆB** | Celery + WebSocket | å®æ—¶äº¤äº’ã€å¤§è§„æ¨¡å¹¶å‘ | åŒå‘é€šä¿¡ã€ä»»åŠ¡è§£è€¦ | æ¶æ„å¤æ‚ã€ä¾èµ–å¤š |

---

#### 3.2 æ–¹æ¡ˆAï¼šSSEæµå¼å“åº”ï¼ˆåŒæ­¥è°ƒç”¨ï¼‰

**æ¶æ„æµç¨‹**ï¼š

```
å‰ç«¯ â†’ Django View â†’ model_loader â†’ æµå¼è¿”å› â†’ å‰ç«¯å®æ—¶æ¥æ”¶
```

**å®ç°ä»£ç **ï¼š

```python
# views.py - QwenChatAPI
def post(self, request):
    prompt = request.data["prompt"]
    session_id = request.data.get("session_id")
    stream_mode = request.data.get("stream", True)

    # è°ƒç”¨æ¨¡å‹ç”Ÿæˆå™¨
    generator = stream_generate_answer(prompt, history=history_data)

    if stream_mode:
        # SSEæµå¼å“åº”
        def event_stream():
            full_answer = ""
            for chunk in generator:
                token = chunk["token"]
                chunk_type = chunk["type"]

                # SSEæ ¼å¼: data: {json}\n\n
                yield f"data: {json.dumps({'code': 200, 'token': token, 'type': chunk_type})}\n\n"

                if chunk_type == "answer":
                    full_answer += token

                if chunk_type == "finish":
                    break

            # ä¿å­˜å¯¹è¯è®°å½•
            ChatRecord.objects.create(
                session_id=session_id,
                role="assistant",
                content=full_answer
            )

        # è¿”å›SSEå“åº”
        response = StreamingHttpResponse(
            event_stream(),
            content_type="text/event-stream"
        )
        response["Cache-Control"] = "no-cache"
        return response
```

**å‰ç«¯æ¥æ”¶ç¤ºä¾‹**ï¼š

```javascript
// å‰ç«¯ä½¿ç”¨ EventSource æ¥æ”¶ SSE æµ
const eventSource = new EventSource('/api/ai/qwen/', {
    method: 'POST',
    body: JSON.stringify({prompt: 'ä½ å¥½', stream: true})
})

eventSource.onmessage = (event) => {
    const data = JSON.parse(event.data)
    console.log(data.token)  // å®æ—¶æ¥æ”¶token

    if (data.type === 'finish') {
        eventSource.close()
    }
}
```

**ä¼˜ç‚¹**ï¼š
- âœ… å®ç°ç®€å•ï¼Œæ— éœ€é¢å¤–æœåŠ¡
- âœ… é€‚åˆå°è§„æ¨¡ã€ä½å¹¶å‘åœºæ™¯

**ç¼ºç‚¹**ï¼š
- âŒ å ç”¨Django Workerï¼Œå¹¶å‘èƒ½åŠ›å—é™
- âŒ å•å‘é€šä¿¡ï¼Œæ— æ³•å®ç°å¿ƒè·³æ£€æµ‹

---

#### 3.3 æ–¹æ¡ˆBï¼šCelery + WebSocketï¼ˆå¼‚æ­¥è§£è€¦ï¼‰

è¿™æ˜¯**ç”Ÿäº§ç¯å¢ƒæ¨èæ–¹æ¡ˆ**ï¼Œå®ç°äº†å®Œæ•´çš„å¼‚æ­¥è§£è€¦æ¶æ„ã€‚

**å®Œæ•´æ•°æ®æµå›¾**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          å‰ç«¯ (Vue3)                             â”‚
â”‚                                                                  â”‚
â”‚  1. POST /api/ai/qwen-async/                                    â”‚
â”‚     {prompt: "ä»‹ç»Python"}                                       â”‚
â”‚                                                                  â”‚
â”‚  â† è¿”å›: {task_id: "abc-123", ws_url: "ws://..."}               â”‚
â”‚                                                                  â”‚
â”‚  2. å»ºç«‹ WebSocket è¿æ¥                                          â”‚
â”‚     ws://localhost:8000/ws/ai/abc-123/                          â”‚
â”‚                                                                  â”‚
â”‚  3. å®æ—¶æ¥æ”¶æ¨é€                                                 â”‚
â”‚     â† {"token": "Python", "type": "answer"}                     â”‚
â”‚     â† {"token": "æ˜¯ä¸€é—¨", "type": "answer"}                     â”‚
â”‚     â† {"token": "", "type": "finish"}                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“ POST                    â†‘ WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Django ASGI (Daphne)                           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  QwenChatAsyncAPI       â”‚    â”‚  AIChatConsumer         â”‚    â”‚
â”‚  â”‚  (RESTè§†å›¾)              â”‚    â”‚  (WebSocketæ¶ˆè´¹è€…)       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚              â”‚                            â”‚                     â”‚
â”‚              â”‚ 1. ç”Ÿæˆ task_id            â”‚                     â”‚
â”‚              â”‚ 2. æäº¤ Celery ä»»åŠ¡        â”‚ 3. åŠ å…¥ Channel     â”‚
â”‚              â”‚ 3. è¿”å› ws_url             â”‚    Group: ai_abc123 â”‚
â”‚              â”‚                            â”‚                     â”‚
â”‚              â†“                            â†“                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Celery Task: qwen_chat_task_streaming                   â”‚  â”‚
â”‚  â”‚  â””â†’ æäº¤åˆ° RabbitMQ é˜Ÿåˆ—                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“ AMQP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       RabbitMQ (æ¶ˆæ¯é˜Ÿåˆ—)                        â”‚
â”‚                                                                  â”‚
â”‚  ä»»åŠ¡é˜Ÿåˆ—: [task_abc123, task_xyz456, ...]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“ Workeræ‹‰å–
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Celery Worker (ç‹¬ç«‹è¿›ç¨‹)                       â”‚
â”‚                                                                  â”‚
â”‚  def qwen_chat_task_streaming(task_id, prompt, history):        â”‚
â”‚      # 1. è°ƒç”¨æ¨¡å‹ç”Ÿæˆå™¨                                         â”‚
â”‚      generator = stream_generate_answer(prompt, history)        â”‚
â”‚                                                                  â”‚
â”‚      # 2. é€tokenæ¨é€åˆ° Redis Channel                           â”‚
â”‚      for chunk in generator:                                    â”‚
â”‚          channel_layer.group_send(                              â”‚
â”‚              f"ai_{task_id}",  # Channel Groupåç§°              â”‚
â”‚              {                                                   â”‚
â”‚                  "type": "ai_message",                          â”‚
â”‚                  "token": chunk["token"],                       â”‚
â”‚                  "chunk_type": chunk["type"]                    â”‚
â”‚              }                                                   â”‚
â”‚          )                                                       â”‚
â”‚                                                                  â”‚
â”‚      # 3. æ¨é€å®Œæˆä¿¡å·                                           â”‚
â”‚      channel_layer.group_send(...)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“ group_send()
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Redis Channel Layer (æ¶ˆæ¯åˆ†å‘)                      â”‚
â”‚                                                                  â”‚
â”‚  Channel Group: ai_abc123                                       â”‚
â”‚  â””â†’ è®¢é˜…è€…: [WebSocket Consumer #1]                             â”‚
â”‚                                                                  â”‚
â”‚  æ¶ˆæ¯é˜Ÿåˆ—:                                                       â”‚
â”‚  [{"type": "ai_message", "token": "Python", ...}]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†‘ group_add()        â†“ è½¬å‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WebSocket Consumer                             â”‚
â”‚                                                                  â”‚
â”‚  async def ai_message(self, event):                             â”‚
â”‚      # æ¥æ”¶æ¥è‡ª Channel Layer çš„æ¶ˆæ¯                             â”‚
â”‚      await self.send(text_data=json.dumps({                     â”‚
â”‚          "code": 200,                                            â”‚
â”‚          "token": event["token"],                               â”‚
â”‚          "type": event["chunk_type"]                            â”‚
â”‚      }))                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“ WebSocketæ¨é€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          å‰ç«¯æ¥æ”¶                                 â”‚
â”‚                                                                  â”‚
â”‚  websocket.onmessage = (msg) => {                               â”‚
â”‚      const data = JSON.parse(msg.data)                          â”‚
â”‚      console.log(data.token)  // å®æ—¶æ˜¾ç¤º                        â”‚
â”‚  }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### 3.4 æ ¸å¿ƒä»£ç å®ç°

**1. REST API - æäº¤ä»»åŠ¡**

```python
# views.py - QwenChatAsyncAPI
class QwenChatAsyncAPI(APIView):
    def post(self, request):
        prompt = request.data["prompt"]
        session_id = request.data.get("session_id") or str(uuid.uuid4())

        # 1. ä¿å­˜ç”¨æˆ·æé—®
        ChatRecord.objects.create(
            session_id=session_id,
            role="user",
            content=prompt
        )

        # 2. è·å–å†å²ä¸Šä¸‹æ–‡
        history_data = list(ChatRecord.objects.filter(
            session_id=session_id
        ).values("role", "content"))

        # 3. ç”Ÿæˆå”¯ä¸€ task_id
        task_id = str(uuid.uuid4())

        # 4. æ„å»º WebSocket URL
        ws_url = f"ws://{request.get_host()}/ws/ai/{task_id}/"

        # 5. æäº¤ Celery å¼‚æ­¥ä»»åŠ¡
        task = qwen_chat_task_streaming.delay(
            task_id=task_id,
            prompt=prompt,
            session_id=session_id,
            history=history_data
        )

        # 6. ä¿å­˜ä»»åŠ¡è®°å½•ï¼ˆç”¨äºç›‘æ§ï¼‰
        AITask.objects.create(
            task_id=task_id,
            celery_task_id=task.id,
            user=request.user,
            session_id=session_id,
            prompt=prompt,
            status='pending',
            ws_url=ws_url
        )

        # 7. è¿”å›ä»»åŠ¡ä¿¡æ¯
        return Response({
            "code": 200,
            "data": {
                "task_id": task_id,
                "celery_task_id": task.id,
                "ws_url": ws_url
            }
        })
```

**2. Celery Task - å¼‚æ­¥æ¨ç†**

```python
# tasks.py
from channels.layers import get_channel_layer
from asgiref.sync import async_to_sync

channel_layer = get_channel_layer()

@shared_task(name='myapps.ai_demo.tasks.qwen_chat_task_streaming', bind=True)
def qwen_chat_task_streaming(self, task_id, prompt, session_id, history):
    """
    AIæµå¼å¯¹è¯ä»»åŠ¡

    å·¥ä½œæµç¨‹ï¼š
    1. Celery Worker æ¥æ”¶ä»»åŠ¡
    2. è°ƒç”¨æ¨¡å‹æµå¼ç”Ÿæˆ
    3. æ¯ç”Ÿæˆä¸€ä¸ªtokenå°±æ¨é€åˆ° Redis Channel
    4. WebSocket Consumer ç›‘å¬å¹¶è½¬å‘ç»™å‰ç«¯
    """
    channel_group_name = f"ai_{task_id}"

    try:
        # è°ƒç”¨æ¨¡å‹ç”Ÿæˆå™¨
        generator = stream_generate_answer(prompt, history=history)

        # é€tokenæ¨é€
        for chunk in generator:
            token = chunk["token"]
            chunk_type = chunk["type"]

            # æ¨é€åˆ° Redis Channel Layer
            async_to_sync(channel_layer.group_send)(
                channel_group_name,
                {
                    "type": "ai_message",  # å¯¹åº” Consumer çš„æ–¹æ³•å
                    "token": token,
                    "chunk_type": chunk_type,
                    "task_id": task_id,
                }
            )

            if chunk_type == "finish":
                break

        return {"status": "success", "task_id": task_id}

    except Exception as e:
        # æ¨é€é”™è¯¯æ¶ˆæ¯
        async_to_sync(channel_layer.group_send)(
            channel_group_name,
            {
                "type": "ai_message",
                "token": f"ç³»ç»Ÿé”™è¯¯: {str(e)}",
                "chunk_type": "error",
            }
        )
        return {"status": "error", "error": str(e)}
```

**3. WebSocket Consumer - æ¶ˆæ¯è½¬å‘**

```python
# consumers.py
from channels.generic.websocket import AsyncWebsocketConsumer
import json

class AIChatConsumer(AsyncWebsocketConsumer):
    """
    WebSocket æ¶ˆè´¹è€…

    èŒè´£ï¼š
    1. æ¥å—å‰ç«¯ WebSocket è¿æ¥
    2. åŠ å…¥ Redis Channel Group
    3. ç›‘å¬ Celery æ¨é€çš„æ¶ˆæ¯
    4. è½¬å‘ç»™å‰ç«¯
    """

    async def connect(self):
        # ä» URL è·å– task_id
        self.task_id = self.scope["url_route"]["kwargs"]["task_id"]
        self.channel_group_name = f"ai_{self.task_id}"

        # åŠ å…¥ Channel Groupï¼ˆè®¢é˜…æ¶ˆæ¯ï¼‰
        await self.channel_layer.group_add(
            self.channel_group_name,
            self.channel_name  # WebSocketè¿æ¥çš„å”¯ä¸€æ ‡è¯†
        )

        # æ¥å— WebSocket è¿æ¥
        await self.accept()

        print(f"âœ… WebSocketè¿æ¥å»ºç«‹: task_id={self.task_id}")

    async def disconnect(self, close_code):
        # ç¦»å¼€ Channel Group
        await self.channel_layer.group_discard(
            self.channel_group_name,
            self.channel_name
        )

        print(f"âŒ WebSocketè¿æ¥æ–­å¼€: task_id={self.task_id}")

    async def receive(self, text_data):
        """
        æ¥æ”¶å‰ç«¯æ¶ˆæ¯ï¼ˆç”¨äºå¿ƒè·³æ£€æµ‹ï¼‰
        """
        data = json.loads(text_data)
        if data.get("type") == "ping":
            await self.send(text_data=json.dumps({"type": "pong"}))

    async def ai_message(self, event):
        """
        æ¥æ”¶æ¥è‡ª Celery çš„æ¶ˆæ¯å¹¶è½¬å‘ç»™å‰ç«¯

        event æ ¼å¼:
        {
            "type": "ai_message",  # æ–¹æ³•åï¼ˆå¿…é¡»åŒ¹é…ï¼‰
            "token": "Python",
            "chunk_type": "answer",
            "task_id": "abc-123"
        }
        """
        # è½¬å‘ç»™å‰ç«¯
        await self.send(text_data=json.dumps({
            "code": 200,
            "token": event["token"],
            "type": event["chunk_type"],
            "task_id": event.get("task_id", self.task_id)
        }))
```

**4. WebSocket è·¯ç”±é…ç½®**

```python
# routing.py
from django.urls import path
from . import consumers

websocket_urlpatterns = [
    path("ws/ai/<str:task_id>/", consumers.AIChatConsumer.as_asgi()),
]

# asgi.py
from channels.routing import ProtocolTypeRouter, URLRouter
from channels.auth import AuthMiddlewareStack

application = ProtocolTypeRouter({
    "http": get_asgi_application(),
    "websocket": AuthMiddlewareStack(
        URLRouter(
            ai_routing.websocket_urlpatterns
        )
    ),
})
```

---

### å››ã€æ•°æ®åº“è®¾è®¡

#### 4.1 æ•°æ®æ¨¡å‹

**AITask - ä»»åŠ¡è®°å½•è¡¨**

```python
class AITask(models.Model):
    """AIä»»åŠ¡è®°å½•ï¼ˆç”¨äºè¿½è¸ªå’Œç›‘æ§ï¼‰"""

    task_id = models.CharField(max_length=100, unique=True, db_index=True)
    celery_task_id = models.CharField(max_length=100, db_index=True)
    user = models.ForeignKey(User, on_delete=models.SET_NULL, null=True)
    session_id = models.CharField(max_length=100, db_index=True)
    prompt = models.TextField()
    status = models.CharField(max_length=20, choices=STATUS_CHOICES)
    ws_url = models.CharField(max_length=500)
    created_at = models.DateTimeField(auto_now_add=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    error_message = models.TextField(blank=True)
```

**ChatRecord - å¯¹è¯è®°å½•è¡¨**

```python
class ChatRecord(models.Model):
    """å¯¹è¯è®°å½•è¡¨"""

    session_id = models.CharField(max_length=100, db_index=True)
    user = models.ForeignKey(User, on_delete=models.SET_NULL, null=True)
    role = models.CharField(max_length=20, choices=[("user", "User"), ("assistant", "AI")])
    content = models.TextField()
    is_hidden = models.BooleanField(default=False)
    created_at = models.DateTimeField(auto_now_add=True)
```

#### 4.2 æ•°æ®å…³ç³»å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       User          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  - id               â”‚
â”‚  - username         â”‚
â”‚  - email            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1:N
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                      â”‚
       â†“ 1:N                  â†“ 1:N
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     AITask          â”‚  â”‚    ChatRecord        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  - task_id (PK)     â”‚  â”‚  - id (PK)           â”‚
â”‚  - celery_task_id   â”‚  â”‚  - session_id (FK)   â”‚
â”‚  - user_id (FK)     â”‚  â”‚  - user_id (FK)      â”‚
â”‚  - session_id       â”‚  â”‚  - role              â”‚
â”‚  - prompt           â”‚  â”‚  - content           â”‚
â”‚  - status           â”‚  â”‚  - created_at        â”‚
â”‚  - ws_url           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  - created_at       â”‚
â”‚  - completed_at     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–æ€»ç»“

### æ¨¡å‹å±‚ä¼˜åŒ–

| ä¼˜åŒ–é¡¹ | å®ç°æ–¹å¼ | æ€§èƒ½æå‡ |
|--------|---------|---------|
| **4-bité‡åŒ–** | BitsAndBytes | æ˜¾å­˜å ç”¨ â†“ 70% |
| **Flash Attention 2** | attn_implementation | æ¨ç†é€Ÿåº¦ â†‘ 25% |
| **KVç¼“å­˜** | use_cache=True | é•¿æ–‡æœ¬æ¨ç† â†‘ 50% |
| **TF32åŠ é€Ÿ** | CUDAé…ç½® | çŸ©é˜µè¿ç®— â†‘ 3x |
| **æœ¬åœ°ç¼“å­˜** | local_files_only | å¯åŠ¨æ—¶é—´ â†“ 15s |

### æ¶æ„å±‚ä¼˜åŒ–

| ä¼˜åŒ–é¡¹ | å®ç°æ–¹å¼ | æ•ˆæœ |
|--------|---------|------|
| **å¼‚æ­¥è§£è€¦** | Celery + WebSocket | å¹¶å‘èƒ½åŠ› â†‘ 10x |
| **Redis Channel** | æ¶ˆæ¯åˆ†å‘ | å®æ—¶æ€§ < 100ms |
| **æµå¼è¾“å‡º** | TextIteratorStreamer | é¦–tokenå»¶è¿Ÿ â†“ 90% |
| **å¤šè¿›ç¨‹Worker** | Celeryå¤šè¿›ç¨‹ | ååé‡ â†‘ 5x |

---

## ğŸ“Š æ¶æ„ä¼˜åŠ¿åˆ†æ

### 1. å¯æ‰©å±•æ€§

```
å•æœºæ¨¡å¼                â†’  åˆ†å¸ƒå¼é›†ç¾¤
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Django (8 Workers)     â†’  Django (32 Workers)
Celery (2 Workers)     â†’  Celery (16 Workers Ã— 4å°æœºå™¨)
Redis (å•å®ä¾‹)          â†’  Redis Cluster (3ä¸»3ä»)
```

### 2. å®¹é”™èƒ½åŠ›

- âœ… **Celeryä»»åŠ¡é‡è¯•**ï¼šå¤±è´¥è‡ªåŠ¨é‡è¯•3æ¬¡
- âœ… **WebSocketæ–­çº¿é‡è¿**ï¼šå‰ç«¯è‡ªåŠ¨é‡è¿æœºåˆ¶
- âœ… **æ¶ˆæ¯æŒä¹…åŒ–**ï¼šRedis AOFæŒä¹…åŒ–
- âœ… **ä»»åŠ¡ç›‘æ§**ï¼šFlowerç›‘æ§é¢æ¿

### 3. ç›‘æ§èƒ½åŠ›

```python
# å®æ—¶ç›‘æ§ç¤ºä¾‹
from celery import current_app

# 1. ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢
task_result = current_app.AsyncResult(celery_task_id)
print(task_result.state)  # PENDING, STARTED, SUCCESS, FAILURE

# 2. WorkerçŠ¶æ€
inspect = current_app.control.inspect()
print(inspect.active())  # æ´»è·ƒä»»åŠ¡
print(inspect.stats())   # Workerç»Ÿè®¡
```

---

## ğŸ¯ éƒ¨ç½²å»ºè®®

### å¼€å‘ç¯å¢ƒ

```bash
# 1. å¯åŠ¨Django (SSEæ–¹æ¡ˆ)
python manage.py runserver

# 2. å¯åŠ¨Daphne (WebSocketæ–¹æ¡ˆ)
daphne -b 0.0.0.0 -p 8000 SkillSpace.asgi:application

# 3. å¯åŠ¨Celery Worker
celery -A SkillSpace worker --loglevel=info --pool=solo

# 4. å¯åŠ¨Flowerç›‘æ§
celery -A SkillSpace flower --port=5555
```

### ç”Ÿäº§ç¯å¢ƒ

```bash
# ä½¿ç”¨ Supervisor ç®¡ç†è¿›ç¨‹
[program:daphne]
command=/path/to/venv/bin/daphne -b 0.0.0.0 -p 8000 SkillSpace.asgi:application
autostart=true
autorestart=true

[program:celery]
command=/path/to/venv/bin/celery -A SkillSpace worker --loglevel=info --concurrency=4
autostart=true
autorestart=true

[program:flower]
command=/path/to/venv/bin/celery -A SkillSpace flower --port=5555
autostart=true
autorestart=true
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆé€‰æ‹© Celery + WebSocket è€Œä¸æ˜¯ç›´æ¥ WebSocketï¼Ÿ

**A**:
- âœ… **ä»»åŠ¡è§£è€¦**ï¼šAIæ¨ç†è€—æ—¶ï¼Œä¸åº”é˜»å¡Django Worker
- âœ… **æ°´å¹³æ‰©å±•**ï¼šCeleryå¯ä»¥éƒ¨ç½²åˆ°å¤šå°GPUæœåŠ¡å™¨
- âœ… **ä»»åŠ¡é˜Ÿåˆ—**ï¼šæ”¯æŒä¼˜å…ˆçº§ã€é‡è¯•ã€å®šæ—¶ä»»åŠ¡
- âœ… **ç›‘æ§èƒ½åŠ›**ï¼šFloweræä¾›å®Œæ•´çš„ä»»åŠ¡ç›‘æ§é¢æ¿

### Q2: Redis Channel Layer çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ

**A**:
- ä½œä¸º **æ¶ˆæ¯ä¸­é—´ä»¶**ï¼Œè¿æ¥ Celery Worker å’Œ WebSocket Consumer
- æ”¯æŒ **å¤šå®ä¾‹éƒ¨ç½²**ï¼ˆå¤šä¸ªDjangoè¿›ç¨‹å…±äº«æ¶ˆæ¯ï¼‰
- æä¾› **group_send** åŠŸèƒ½ï¼ˆä¸€å¯¹å¤šå¹¿æ’­ï¼‰

### Q3: å¦‚ä½•åˆ‡æ¢åˆ°é˜¿é‡Œäº‘åƒé—®APIï¼Ÿ

**A**:
```python
# 1. è®¾ç½®ç¯å¢ƒå˜é‡
AI_ENGINE=alibaba
DASHSCOPE_API_KEY=sk-xxx

# 2. ä¿®æ”¹ model_loader.py
if AI_ENGINE == "alibaba":
    from .alibaba_api import AlibabaDashScopeEngine
    return AlibabaDashScopeEngine().stream_generate(prompt, history)
```

---

## ğŸ“š å‚è€ƒèµ„æº

- **Django Channelsæ–‡æ¡£**: https://channels.readthedocs.io/
- **Celeryæ–‡æ¡£**: https://docs.celeryproject.org/
- **Transformersæ–‡æ¡£**: https://huggingface.co/docs/transformers/
- **é˜¿é‡Œäº‘ç™¾ç‚¼API**: https://help.aliyun.com/zh/dashscope/

---

## ğŸ“ æ€»ç»“

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ª**ç”Ÿäº§çº§çš„AIå¯¹è¯ç³»ç»Ÿ**ï¼Œæ ¸å¿ƒäº®ç‚¹ï¼š

1. âœ… **åŒå¼•æ“æ”¯æŒ**ï¼šæœ¬åœ°Qwenæ¨¡å‹ + äº‘ç«¯APIåˆ‡æ¢
2. âœ… **åŒæ¨¡å¼è¾“å‡º**ï¼šSSEæµå¼ + WebSocketæµå¼
3. âœ… **å®Œæ•´å¼‚æ­¥æ¶æ„**ï¼šCelery + RabbitMQ + Redis + WebSocket
4. âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼š4-bité‡åŒ–ã€Flash Attention 2ã€KVç¼“å­˜
5. âœ… **å¯æ‰©å±•è®¾è®¡**ï¼šæ”¯æŒæ°´å¹³æ‰©å±•ã€ä»»åŠ¡ç›‘æ§ã€å®¹é”™é‡è¯•

è¿™ä¸ªæ¶æ„å¯ä»¥æ”¯æ’‘**åƒçº§å¹¶å‘ã€ç§’çº§å“åº”**çš„ç”Ÿäº§ç¯å¢ƒéœ€æ±‚ï¼ğŸš€
