#!/usr/bin/env python
"""
AIå†…å®¹é‡ä¼˜åŒ–æ•ˆæœæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯ä¿®æ”¹åçš„AIå›å¤é•¿åº¦å’Œè´¨é‡

ä½¿ç”¨æ–¹æ³•ï¼š
  cd e:\skillSpace\backend
  .\sk_venv\Scripts\Activate.ps1
  python test_ai_improvement.py
"""

import os
import sys
import django

# é…ç½® Django ç¯å¢ƒ
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'SkillSpace.settings')
django.setup()

from myapps.ai_demo.model_loader import stream_generate_answer

# æµ‹è¯•æç¤ºè¯é›†åˆï¼ˆä»ç®€åˆ°å¤æ‚ï¼‰
TEST_PROMPTS = [
    # ç®€å•é—®é¢˜
    "ä»€ä¹ˆæ˜¯Pythonè£…é¥°å™¨ï¼Ÿ",
    
    # ä¸­ç­‰é—®é¢˜
    "è¯·è¯¦ç»†è§£é‡ŠPythonè£…é¥°å™¨çš„å®ç°åŸç†å’Œå¸¸è§åº”ç”¨åœºæ™¯",
    
    # å¤æ‚é—®é¢˜
    "è¯·è¯¦ç»†ä»‹ç»Pythonçš„è£…é¥°å™¨æ¨¡å¼ï¼ŒåŒ…æ‹¬å®ç°åŸç†ã€å¸¸è§ç”¨é€”ã€æœ€ä½³å®è·µå’Œæ€§èƒ½è€ƒè™‘ã€‚ä¸¾ä¸ªå¤æ‚çš„ä¾‹å­ã€‚",
]

def test_ai_response(prompt, test_num=1):
    """æµ‹è¯•å•ä¸ªAIå›å¤"""
    print(f"\n{'='*80}")
    print(f"æµ‹è¯• #{test_num}: {prompt[:60]}...")
    print(f"{'='*80}")
    
    full_response = ""
    token_count = 0
    chunk_count = 0
    
    try:
        for chunk in stream_generate_answer(prompt):
            token = chunk.get("token", "")
            chunk_type = chunk.get("type", "")
            
            if chunk_type == "answer":
                full_response += token
                token_count += 1
                chunk_count += 1
            elif chunk_type == "finish":
                print(f"\nâœ… AIå›å¤å·²å®Œæˆ")
                break
            elif chunk_type == "error":
                print(f"âŒ é”™è¯¯: {token}")
                return None
        
        # ç»Ÿè®¡ä¿¡æ¯
        char_count = len(full_response)
        word_count = len(full_response.split())
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  â€¢ å­—ç¬¦æ•°: {char_count}")
        print(f"  â€¢ ä¸­æ–‡å­—æ•°ï¼ˆä¼°ç®—ï¼‰: {int(char_count * 0.6)}")  # ä¸­æ–‡é€šå¸¸å 60%
        print(f"  â€¢ Tokenæ•°: {token_count}")
        print(f"  â€¢ è¯æ•°: {word_count}")
        print(f"  â€¢ å¹³å‡Tokené•¿åº¦: {char_count/token_count:.1f} å­—ç¬¦/token" if token_count > 0 else "")
        
        print(f"\nğŸ“ å›å¤å†…å®¹ï¼ˆå‰500å­—ï¼‰:")
        print("-" * 80)
        print(full_response[:500])
        if len(full_response) > 500:
            print(f"... ï¼ˆçœç•¥ï¼Œå…±{char_count}å­—ï¼‰")
        print("-" * 80)
        
        return {
            "prompt": prompt,
            "response": full_response,
            "char_count": char_count,
            "token_count": token_count,
            "word_count": word_count
        }
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\nğŸš€ AIå†…å®¹é‡ä¼˜åŒ–æ•ˆæœæµ‹è¯•")
    print("=" * 80)
    print("æœ¬è„šæœ¬æµ‹è¯•ä»¥ä¸‹ä¼˜åŒ–é¡¹ï¼š")
    print("  âœ… max_new_tokens: 2048 â†’ 4096")
    print("  âœ… temperature: 0.7 â†’ 0.8")
    print("  âœ… top_p: 0.8 â†’ 0.9")
    print("  âœ… top_k: 40 â†’ 50")
    print("  âœ… System Prompt: ç§»é™¤å¼ºåˆ¶XMLæ ¼å¼")
    print("  âœ… æµå¼å¤„ç†: ç®€åŒ–XMLè§£æ")
    print("=" * 80)
    
    results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    for idx, prompt in enumerate(TEST_PROMPTS, 1):
        result = test_ai_response(prompt, test_num=idx)
        if result:
            results.append(result)
        # æµ‹è¯•é—´éš”ï¼Œé¿å…æ˜¾å­˜æº¢å‡º
        if idx < len(TEST_PROMPTS):
            input("\næŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")
    
    # æ€»ç»“æŠ¥å‘Š
    if results:
        print("\n" + "=" * 80)
        print("ğŸ“Š æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print("=" * 80)
        
        total_chars = sum(r["char_count"] for r in results)
        total_tokens = sum(r["token_count"] for r in results)
        avg_chars = total_chars / len(results) if results else 0
        
        print(f"\næµ‹è¯•æ•°é‡: {len(results)}")
        print(f"æ€»å­—ç¬¦æ•°: {total_chars}")
        print(f"æ€»Tokenæ•°: {total_tokens}")
        print(f"å¹³å‡å›å¤å­—ç¬¦æ•°: {avg_chars:.0f}")
        print(f"å¹³å‡Tokenæ•°: {total_tokens/len(results):.0f}")
        
        print(f"\nâœ… ä¼˜åŒ–ç›®æ ‡æ£€æŸ¥:")
        if avg_chars > 1000:
            print(f"  âœ… å†…å®¹é‡å……è¶³ï¼ˆ>1000å­—ï¼‰: å®é™… {avg_chars:.0f} å­—")
        else:
            print(f"  âš ï¸  å†…å®¹é‡åå°‘ï¼ˆ<1000å­—ï¼‰: å®é™… {avg_chars:.0f} å­—")
        
        if all(r["char_count"] > 500 for r in results):
            print(f"  âœ… æ¯ä¸ªå›å¤éƒ½>500å­—")
        else:
            print(f"  âš ï¸  æœ‰å›å¤<500å­—")
        
        # æ£€æŸ¥å›å¤å®Œæ•´æ€§
        incomplete = [r for r in results if not r["response"].strip().endswith('ã€‚')]
        if not incomplete:
            print(f"  âœ… æ‰€æœ‰å›å¤å®Œæ•´æ€§è‰¯å¥½ï¼ˆä»¥ã€‚ç»“å°¾ï¼‰")
        else:
            print(f"  âš ï¸  {len(incomplete)}ä¸ªå›å¤å¯èƒ½è¢«æˆªæ–­")
        
        print("\nğŸ’¡ å»ºè®®:")
        if avg_chars > 1500:
            print("  âœ… ä¼˜åŒ–æ•ˆæœæ˜¾è‘—ï¼Œå†…å®¹é‡å·²æ˜æ˜¾æå‡")
        elif avg_chars > 1000:
            print("  âœ… ä¼˜åŒ–æ•ˆæœè‰¯å¥½ï¼Œå†…å®¹é‡å·²æ”¹å–„")
        else:
            print("  âš ï¸  å†…å®¹é‡ä»éœ€æ”¹è¿›ï¼Œå¯è€ƒè™‘ï¼š")
            print("     - è¿›ä¸€æ­¥å¢åŠ  max_new_tokens")
            print("     - æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½")
            print("     - æ£€æŸ¥GPUæ˜¾å­˜æ˜¯å¦å……è¶³")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•å·²ä¸­æ­¢")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è„šæœ¬é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
