#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é˜¿é‡Œäº‘é€šä¹‰åƒé—® API è¿æ¥æµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. æµ‹è¯• API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
2. æµ‹è¯•æµå¼å“åº”æ˜¯å¦æ­£å¸¸
3. éªŒè¯è¿”å›æ ¼å¼æ˜¯å¦ç¬¦åˆé¢„æœŸ

ä½¿ç”¨æ–¹æ³•ï¼š
    python test_ai_api.py
"""

import os
import sys
from pathlib import Path

# è®¾ç½®è¾“å‡ºç¼–ç ä¸º UTF-8
if sys.platform == "win32":
    import io

    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent / "SkillSpace"
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv

# å°è¯•åŠ è½½ .env.production æˆ– .env
env_file = Path(__file__).parent.parent.parent / ".env.production"
if not env_file.exists():
    env_file = Path(__file__).parent.parent / ".env"

print(f"ğŸ“ åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_file}")
load_dotenv(env_file)

# æ˜¾ç¤ºå½“å‰é…ç½®
print("\n" + "=" * 60)
print("ğŸ“‹ å½“å‰ AI å¼•æ“é…ç½®")
print("=" * 60)
print(f"USE_AI_API: {os.getenv('USE_AI_API', 'false')}")
print(f"ALIYUN_API_KEY: {os.getenv('ALIYUN_API_KEY', 'æœªé…ç½®')[:20]}...")
print(f"ALIYUN_BASE_URL: {os.getenv('ALIYUN_BASE_URL', 'æœªé…ç½®')}")
print(f"ALIYUN_MODEL_NAME: {os.getenv('ALIYUN_MODEL_NAME', 'qwen-plus')}")
print("=" * 60)

# æµ‹è¯• API è¿æ¥
try:
    from openai import OpenAI

    print("\nğŸš€ å¼€å§‹æµ‹è¯•é˜¿é‡Œäº‘ API è¿æ¥...\n")

    # è·å–é…ç½®
    api_key = os.getenv("ALIYUN_API_KEY")
    base_url = os.getenv("ALIYUN_BASE_URL")
    model_name = os.getenv("ALIYUN_MODEL_NAME", "qwen-plus")

    if not api_key or not base_url:
        print("âŒ é”™è¯¯: ALIYUN_API_KEY æˆ– ALIYUN_BASE_URL æœªé…ç½®")
        sys.exit(1)

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(api_key=api_key, base_url=base_url)

    # æµ‹è¯•æç¤ºè¯
    test_prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç» Python ç¼–ç¨‹è¯­è¨€ã€‚"

    print(f"ğŸ’¬ æµ‹è¯•æç¤ºè¯: {test_prompt}\n")
    print("ğŸ“¡ å‘é€è¯·æ±‚åˆ°é˜¿é‡Œäº‘ API...\n")

    # å‘é€æµå¼è¯·æ±‚
    response = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": test_prompt},
        ],
        stream=True,
        temperature=0.7,
    )

    # æ¥æ”¶æµå¼å“åº”
    print("âœ… API è¿æ¥æˆåŠŸï¼å¼€å§‹æ¥æ”¶æµå¼å“åº”:\n")
    print("-" * 60)

    full_response = ""
    token_count = 0

    for chunk in response:
        if chunk.choices[0].delta.content is not None:
            token = chunk.choices[0].delta.content
            full_response += token
            token_count += 1
            print(token, end="", flush=True)

    print("\n" + "-" * 60)
    print("\nğŸ“Š å“åº”ç»Ÿè®¡:")
    print(f"   - Token æ•°é‡: {token_count}")
    print(f"   - å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦")
    print("\nâœ… æµ‹è¯•å®Œæˆï¼é˜¿é‡Œäº‘ API å·¥ä½œæ­£å¸¸ã€‚")

except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("æç¤º: è¯·ç¡®ä¿å·²å®‰è£… openai åº“: pip install openai")
    sys.exit(1)

except Exception as e:
    print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
    import traceback

    traceback.print_exc()
    sys.exit(1)
